## ðŸ“˜ Deception Decoder: A Human-Centred Framework for Detecting AI-Generated Mis/Disinformation

**Deception Decoder** is a human-focused, multimodal framework designed to help users identify AI-generated misinformation and disinformation across text, images, and videoâ€”particularly on social media platforms. Unlike most existing solutions, which rely heavily on automated or machine learningâ€“based detection, this framework empowers individuals through critical engagement and visual literacy, offering a structured method for spotting 'red flags' in AI-generated content.

Developed as part of an honours dissertation at Queen Margaret University, this framework was informed by a comparative analysis of existing detection models, a content analysis of state-of-the-art AI-generated video samples, as well as participatory focus group study. The result is a systematic and adaptable toolâ€”composed of three interconnected layers:

- **Source** â€“ Evaluates the trustworthiness of a contentâ€™s origin.
- **Content** â€“ Identifies linguistic and visual anomalies typical of AI-generated material.
- **Motive** â€“ Assesses the likely intent behind the contentâ€™s creation and distribution.

The framework is designed for general users, educators, and media literacy advocates seeking accessible, research-based tools to navigate the increasingly complex information ecosystem shaped by generative AI.

---
![CC0](https://licensebuttons.net/p/zero/1.0/88x31.png) This project is released under the [Creative Commons Zero 1.0 Universal license (CC0)](https://creativecommons.org/publicdomain/zero/1.0/), meaning youâ€™re free to use, remix, adapt, and build upon it without restriction.
